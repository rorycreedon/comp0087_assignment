{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "930da54deb504a92948362b8fc3fd21c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e8c63bab5414f0fb62952fcc1a61b44",
              "IPY_MODEL_9a30daaa8e714bc0b130048ffe8f8652",
              "IPY_MODEL_3b6bcc00a19f44f59ead07e59b6746fd"
            ],
            "layout": "IPY_MODEL_f20f301d3e6243f0884fb9f6d5a00557"
          }
        },
        "3e8c63bab5414f0fb62952fcc1a61b44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c7d629486da4f7b81fe51c21b72e65e",
            "placeholder": "​",
            "style": "IPY_MODEL_9398a4fa06cd4e5a92948c7532a357a0",
            "value": "100%"
          }
        },
        "9a30daaa8e714bc0b130048ffe8f8652": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e8dc1b7c8aa4b528014a220ae2f492f",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_235690bee02745d2b2e23f38ac5be39d",
            "value": 3
          }
        },
        "3b6bcc00a19f44f59ead07e59b6746fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86739a4c7eb84973803ded117c6e4c0d",
            "placeholder": "​",
            "style": "IPY_MODEL_3b82f095ea504eef838ca0a4c40b95e2",
            "value": " 3/3 [00:00&lt;00:00, 68.20it/s]"
          }
        },
        "f20f301d3e6243f0884fb9f6d5a00557": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c7d629486da4f7b81fe51c21b72e65e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9398a4fa06cd4e5a92948c7532a357a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e8dc1b7c8aa4b528014a220ae2f492f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "235690bee02745d2b2e23f38ac5be39d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "86739a4c7eb84973803ded117c6e4c0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b82f095ea504eef838ca0a4c40b95e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Statistical Natural Language Processing (COMP0087) Demo Notebook\n",
        "---\n",
        "---\n",
        "Greetings and welcome to our demo notebook for our NLP research project! Within this notebook, we will be presenting an automatic text summarisation technique and demonstrating its effectiveness in generating brief summaries of lengthy legal documents. We will then import three of our pre-trained models that are specifically designed for this summarisation method, including binary, multi-class classification, and regression models, and apply them to our withheld test set. For the purpose of this demonstration, we will focus solely on the Long-T5 model for text summarisation."
      ],
      "metadata": {
        "id": "jVeeQF2T8vyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports and pip installs\n",
        "!pip install gdown --quiet\n",
        "!pip install datasets --quiet\n",
        "!pip install transformers --quiet\n",
        "!pip install sumy --quiet\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import gdown\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import AutoTokenizer, LongT5ForConditionalGeneration, AutoModel\n",
        "from sklearn.metrics import classification_report, mean_absolute_error\n",
        "from tqdm.notebook import tqdm\n",
        "from pathlib import Path\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division, print_function, unicode_literals\n",
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
        "from sumy.summarizers.text_rank import TextRankSummarizer\n",
        "from sumy.summarizers.reduction import ReductionSummarizer\n",
        "from sumy.nlp.stemmers import Stemmer\n",
        "from sumy.utils import get_stop_words\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "# led_url = \"https://drive.google.com/drive/u/2/folders/1-gj7w6zxUiyHlz43I3gayV-QjN7EjL_c\"\n",
        "# tr_url = \"https://drive.google.com/drive/folders/14wCaRAp9wGe97srtzeVxAfnTvL3ynOkF?usp=sharing\"\n",
        "# model1_url = \"https://drive.google.com/drive/folders/17Kke3WwGsnY6MGQIHphPekXA0N7V2Gvu?usp=sharing\"\n",
        "url_lt5 = \"https://drive.google.com/drive/folders/1okkRzSbEwjAQMgib1tfqAfx3rlmzcqpp?usp=sharing\"\n",
        "model_lt5_url = \"https://drive.google.com/drive/folders/1JB1oaKR2ymt-HHMmlCL8sP_DJf8-iK6m?usp=sharing\"\n",
        "gdown.download_folder(url_lt5)\n",
        "gdown.download_folder(model_lt5_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyPSUJzW-QL-",
        "outputId": "c909b413-0783-4bdc-ea63-1f200948cd79"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "Retrieving folder list\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file 1-0HfMsdn4bAVxz_RrCJ-tZc_g7JlCuq0 anon_test.pkl\n",
            "Processing file 1dlxnn2sPaCnGYoy9CEZ3nPRTywvbScmb anon_train.pkl\n",
            "Processing file 1-AnGpzloxNUYQNDmNbU4CqtIpboU117t anon_valid.pkl\n",
            "Processing file 1-1y03q8cvGyRhq0JQob7hZ8Q_VWyIp5b non-anon_test.pkl\n",
            "Processing file 1Pu1ShrXaw7jfao6povJeHKHD29qB7ffJ non-anon_train.pkl\n",
            "Processing file 1dR0YI60OKTjSw5R2fXSD41-nMEpTAo3f non-anon_valid.pkl\n",
            "Building directory structure completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder list completed\n",
            "Building directory structure\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-0HfMsdn4bAVxz_RrCJ-tZc_g7JlCuq0\n",
            "To: /content/long_t5_summary/anon_test.pkl\n",
            "100%|██████████| 33.6M/33.6M [00:00<00:00, 54.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1dlxnn2sPaCnGYoy9CEZ3nPRTywvbScmb\n",
            "To: /content/long_t5_summary/anon_train.pkl\n",
            "100%|██████████| 103M/103M [00:00<00:00, 235MB/s] \n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-AnGpzloxNUYQNDmNbU4CqtIpboU117t\n",
            "To: /content/long_t5_summary/anon_valid.pkl\n",
            "100%|██████████| 21.2M/21.2M [00:00<00:00, 205MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-1y03q8cvGyRhq0JQob7hZ8Q_VWyIp5b\n",
            "To: /content/long_t5_summary/non-anon_test.pkl\n",
            "100%|██████████| 39.4M/39.4M [00:00<00:00, 166MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Pu1ShrXaw7jfao6povJeHKHD29qB7ffJ\n",
            "To: /content/long_t5_summary/non-anon_train.pkl\n",
            "100%|██████████| 113M/113M [00:00<00:00, 203MB/s] \n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1dR0YI60OKTjSw5R2fXSD41-nMEpTAo3f\n",
            "To: /content/long_t5_summary/non-anon_valid.pkl\n",
            "100%|██████████| 23.2M/23.2M [00:00<00:00, 196MB/s]\n",
            "Download completed\n",
            "Retrieving folder list\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file 18LsuCi8z__elW4BBkzSpdz6zUVuIRBMP long_t5_opt_binary_cls.pt\n",
            "Processing file 155Np_Cw0Jfup44gERNhiEKc4iGr2bdU9 long_t5_opt_multi_cls.pt\n",
            "Processing file 16IR_6ENYoTJj75yr36yj8cCsNtefW4wQ long_t5_opt_regression.pt\n",
            "Building directory structure completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder list completed\n",
            "Building directory structure\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=18LsuCi8z__elW4BBkzSpdz6zUVuIRBMP\n",
            "To: /content/long_t5_binary_cls/long_t5_opt_binary_cls.pt\n",
            "100%|██████████| 140M/140M [00:00<00:00, 219MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=155Np_Cw0Jfup44gERNhiEKc4iGr2bdU9\n",
            "To: /content/long_t5_binary_cls/long_t5_opt_multi_cls.pt\n",
            "100%|██████████| 140M/140M [00:00<00:00, 232MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=16IR_6ENYoTJj75yr36yj8cCsNtefW4wQ\n",
            "To: /content/long_t5_binary_cls/long_t5_opt_regression.pt\n",
            "100%|██████████| 140M/140M [00:01<00:00, 109MB/s] \n",
            "Download completed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/long_t5_binary_cls/long_t5_opt_binary_cls.pt',\n",
              " '/content/long_t5_binary_cls/long_t5_opt_multi_cls.pt',\n",
              " '/content/long_t5_binary_cls/long_t5_opt_regression.pt']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Data\n",
        "---\n",
        "In this section of the notebook, we download and explain the ECHR dataset used in this research project.\n"
      ],
      "metadata": {
        "id": "don-N73B_wkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ECHR DATASET\n",
        "def clean_echr(df):\n",
        "    \"\"\"\n",
        "    Clean ECHR dataset.\n",
        "    Params:\n",
        "    `df` (pd.DataFrame): dataframe to clean\n",
        "    \"\"\"\n",
        "\n",
        "    # Drop rows where language is not English\n",
        "    if (np.unique(df['languageisocode']) == 'ENG')!=True:\n",
        "        df = df[df['languageisocode'] == 'ENG']\n",
        "\n",
        "    # Drop rows where text is empty\n",
        "    df = df[df['text'].apply(lambda x: len(x)) > 0]\n",
        "\n",
        "    # Convert array of strings to string in the 'text' column\n",
        "    df['text'] = df['text'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "    # Dummy variable for when conclusion = 'Inadmissible'\n",
        "    df['inadmissible'] = df['conclusion'] == 'Inadmissible'\n",
        "\n",
        "    # Create column for articles raised\n",
        "    df['all_articles'] = df['violated_articles'] + df['non_violated_articles'] \n",
        "\n",
        "    # Keep only columns of interest\n",
        "    df = df[['itemid', 'text', 'violated_articles', 'violated', 'non_violated_articles', 'all_articles', 'importance', 'inadmissible', 'date', 'docname']]\n",
        "\n",
        "    return df\n",
        "\n",
        "def download_echr(name):\n",
        "    \"\"\"\n",
        "    Download and clean ECHR dataset from Hugging Face datasets library.\n",
        "    Params:\n",
        "    `name` (str): name of dataset to download, either 'anon' or 'non-anon'\n",
        "    \"\"\"\n",
        "\n",
        "    # Check if name is valid\n",
        "    if name not in ['anon', 'non-anon']:\n",
        "        raise ValueError(\"Name must be either 'anon' or 'non-anon'\")\n",
        "\n",
        "    # Download dataset\n",
        "    data = load_dataset(path = \"jonathanli/echr\", name = name)\n",
        "\n",
        "    # Convert test, train and validation to dataframes\n",
        "    test_df = pd.DataFrame(data['test'])\n",
        "    train_df = pd.DataFrame(data['train'])\n",
        "    valid_df = pd.DataFrame(data['validation'])\n",
        "\n",
        "    # Clean each dataframe\n",
        "    test_df = clean_echr(test_df)\n",
        "    train_df = clean_echr(train_df)\n",
        "    valid_df = clean_echr(valid_df)\n",
        "\n",
        "    # Make data and echr folder if necessary\n",
        "    if not os.path.exists('data'):\n",
        "        os.mkdir('data')\n",
        "    if not os.path.exists('data/echr'):\n",
        "        os.mkdir('data/echr')\n",
        "\n",
        "    # Save each dataframe to pickle file\n",
        "    test_df.to_pickle(f'data/echr/{name}_test.pkl')\n",
        "    train_df.to_pickle(f'data/echr/{name}_train.pkl')\n",
        "    valid_df.to_pickle(f'data/echr/{name}_valid.pkl')\n",
        "\n",
        "# Download and clean ECHR datasets\n",
        "download_echr('non-anon')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "930da54deb504a92948362b8fc3fd21c",
            "3e8c63bab5414f0fb62952fcc1a61b44",
            "9a30daaa8e714bc0b130048ffe8f8652",
            "3b6bcc00a19f44f59ead07e59b6746fd",
            "f20f301d3e6243f0884fb9f6d5a00557",
            "9c7d629486da4f7b81fe51c21b72e65e",
            "9398a4fa06cd4e5a92948c7532a357a0",
            "9e8dc1b7c8aa4b528014a220ae2f492f",
            "235690bee02745d2b2e23f38ac5be39d",
            "86739a4c7eb84973803ded117c6e4c0d",
            "3b82f095ea504eef838ca0a4c40b95e2"
          ]
        },
        "id": "M0c3hwbaBy7L",
        "outputId": "01f16d33-5c79-4168-f154-78a9da72843e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset echr (/root/.cache/huggingface/datasets/jonathanli___echr/non-anon/0.0.0/9a301df70cd2e4ae7adac519dbf5b2b588fb922a515467049a544f5f533f08eb)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "930da54deb504a92948362b8fc3fd21c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The ECHR Dataset:\n",
        "\n",
        "The ECHR (European Court of Human Rights) dataset is a corpus of legal texts and consists of roughly 11.5k court cases sourced from the ECHR public database, with each case containing the relevant facts leading to the judgement. Each datapoint consists of a legal case, a binary varaible indicating whether a European Court of Human Rights article was breached, a multi-class variable of which article was breached, and an importance rating from 1-4 on the score of the case assigned by the ECHR.\n"
      ],
      "metadata": {
        "id": "O381TiVsIywD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read the data\n",
        "df = pd.read_pickle(\"data/echr/non-anon_train.pkl\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1R1_bw0LCrxW",
        "outputId": "3cfc02a0-9b61-4789-81d7-816fc8055a41"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       itemid                                               text  \\\n",
              "0   001-60714  The applicant was born in 1943 and lives in La...   \n",
              "1  001-100920  The applicant, Mr Panayiotis Panayi, is a Cypr...   \n",
              "2   001-77249  The Salvation Army worked officially in Russia...   \n",
              "3    001-4589  The applicant is a British national, born in 1...   \n",
              "4   001-83374  The applicant was born in 1967 and lives in Li...   \n",
              "\n",
              "  violated_articles  violated non_violated_articles all_articles  importance  \\\n",
              "0               [6]      True                    []          [6]           4   \n",
              "1                []     False                    []           []           4   \n",
              "2           [11, 9]      True                    []      [11, 9]           1   \n",
              "3                []     False                    []           []           4   \n",
              "4               [5]      True                    []          [5]           3   \n",
              "\n",
              "   inadmissible  date                                            docname  \n",
              "0         False  2002                     CASE OF PIETILAINEN v. FINLAND  \n",
              "1          True  2010                                   PANAYI v. CYPRUS  \n",
              "2         False  2006  CASE OF THE MOSCOW BRANCH OF THE SALVATION ARM...  \n",
              "3          True  1999                         A.J. v. THE UNITED KINGDOM  \n",
              "4         False  2007                CASE OF GAULT v. THE UNITED KINGDOM  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f82ae767-e7d6-4026-a79f-caf83ca4581b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>itemid</th>\n",
              "      <th>text</th>\n",
              "      <th>violated_articles</th>\n",
              "      <th>violated</th>\n",
              "      <th>non_violated_articles</th>\n",
              "      <th>all_articles</th>\n",
              "      <th>importance</th>\n",
              "      <th>inadmissible</th>\n",
              "      <th>date</th>\n",
              "      <th>docname</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>001-60714</td>\n",
              "      <td>The applicant was born in 1943 and lives in La...</td>\n",
              "      <td>[6]</td>\n",
              "      <td>True</td>\n",
              "      <td>[]</td>\n",
              "      <td>[6]</td>\n",
              "      <td>4</td>\n",
              "      <td>False</td>\n",
              "      <td>2002</td>\n",
              "      <td>CASE OF PIETILAINEN v. FINLAND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>001-100920</td>\n",
              "      <td>The applicant, Mr Panayiotis Panayi, is a Cypr...</td>\n",
              "      <td>[]</td>\n",
              "      <td>False</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>4</td>\n",
              "      <td>True</td>\n",
              "      <td>2010</td>\n",
              "      <td>PANAYI v. CYPRUS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>001-77249</td>\n",
              "      <td>The Salvation Army worked officially in Russia...</td>\n",
              "      <td>[11, 9]</td>\n",
              "      <td>True</td>\n",
              "      <td>[]</td>\n",
              "      <td>[11, 9]</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>2006</td>\n",
              "      <td>CASE OF THE MOSCOW BRANCH OF THE SALVATION ARM...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>001-4589</td>\n",
              "      <td>The applicant is a British national, born in 1...</td>\n",
              "      <td>[]</td>\n",
              "      <td>False</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>4</td>\n",
              "      <td>True</td>\n",
              "      <td>1999</td>\n",
              "      <td>A.J. v. THE UNITED KINGDOM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>001-83374</td>\n",
              "      <td>The applicant was born in 1967 and lives in Li...</td>\n",
              "      <td>[5]</td>\n",
              "      <td>True</td>\n",
              "      <td>[]</td>\n",
              "      <td>[5]</td>\n",
              "      <td>3</td>\n",
              "      <td>False</td>\n",
              "      <td>2007</td>\n",
              "      <td>CASE OF GAULT v. THE UNITED KINGDOM</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f82ae767-e7d6-4026-a79f-caf83ca4581b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f82ae767-e7d6-4026-a79f-caf83ca4581b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f82ae767-e7d6-4026-a79f-caf83ca4581b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example Legal Case:\n",
        "\n",
        "This is an example of the raw legal case text data. The dataset provides a list of facts extractd using regular expressions from the case description.\n",
        "\n",
        "----\n",
        "\n",
        "\n",
        "The applicant was born in 1943 and lives in Laukaa. On 5 January 1987 criminal investigations were instituted against the applicant who was taken into police custody the same day in respect of, inter alia, alleged tax frauds. He was released on 16 January 1987. On 5 July and 31 August 1990 the applicant was summoned to appear before the Helsinki City Court (raastuvanoikeus, rådstuvurätt, as from 1 December 1993 Helsinki District Court, käräjäoikeus, tingsrätt) indicted for several aggravated tax frauds. The alleged offences concerned the importation of parts of vehicles and failure to pay relevant tax for them ..."
      ],
      "metadata": {
        "id": "U2tZTEpJDRrt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Automatic Text Summarisation\n",
        "---\n",
        "In this section we showcase one of the seven automatic text summarisation methods that were used in our research project - Long-T5 - and demonstrate how it can be used to generate accurate and concise summaries of long legal case information. Long-T5 is an abstractive transformer model that generates summaries by predicting the most likely words to appear in a summary, given the input text.\n",
        "\n",
        "<!-- In this section we showcase two automatic text summarisation methods that were used in our research project - TextRank and Long-T5 - and demonstrate how they can be used to generate accurate and concise summaries of long legal case information. TextRank is an extractive graph-based method that uses the PageRank algorithm to identify the most important sentences in a document and generate a summary based on those sentences. On the other hand, Long-T5 is an abstractive transformer model that generates summaries by predicting the most likely words to appear in a summary, given the input text. -->\n",
        "\n"
      ],
      "metadata": {
        "id": "MhNSV1zF-L3i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1. Abstractive Text Summarisation Example (Long-T5)\n",
        "\n",
        "For demonstration purposes we will produce summaries for the first 10 case texts in the non-anonymised ECHR training set."
      ],
      "metadata": {
        "id": "s-MwRIGjJPiO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for summarisation\n",
        "def summarise(texts, tokenizer, model, device, min_summary_legnth, max_summary_length):\n",
        "    \"\"\"\n",
        "    Summarise a batch of texts.\n",
        "    Args:\n",
        "        texts (list): list of texts to be summarised.\n",
        "        tokenizer (transformers.models.led.tokenization_led_fast.LEDTokenizerFast): tokenizer for the summarisation model.\n",
        "        model (transformers.models.led.modeling_led.LEDForConditionalGeneration): model for summarisation.\n",
        "        device (str): device to run the model on. Either 'cpu' or 'cuda'.\n",
        "        min_summary_length (int): minimum length of the summary.\n",
        "        max_summary_length (int): maximum length of the summary.\n",
        "    Returns:\n",
        "        batch_summaries (list): batch of summaries.\n",
        "    \"\"\"\n",
        "    # tokenize the batch of texts\n",
        "    inputs = tokenizer.batch_encode_plus(texts, return_tensors='pt', padding=True, truncation=True, max_length=10000).to(device)\n",
        "    \n",
        "    # generate summaries for the batch of texts\n",
        "    summary_ids = model.generate(inputs.input_ids, attention_mask=inputs.attention_mask, max_length=max_summary_length, min_length = min_summary_legnth)\n",
        "    \n",
        "    # decode the summary ids back into text\n",
        "    batch_summaries = tokenizer.batch_decode(summary_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
        "    \n",
        "    return batch_summaries\n",
        "\n",
        "# move to GPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# longT5 model and tokenizer\n",
        "model = LongT5ForConditionalGeneration.from_pretrained(\"google/long-t5-tglobal-base\").to(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/long-t5-tglobal-base\")\n",
        "\n",
        "if \"summary\" not in df.columns:\n",
        "  df[\"summary\"] = \"\"\n",
        "\n",
        "batch_size = 2\n",
        "for j in range(5):\n",
        "  start_idx = j*batch_size\n",
        "  end_idx = (j+1)*batch_size\n",
        "  texts = df['text'][start_idx:end_idx].tolist()\n",
        "  batch_summaries = summarise(texts, tokenizer, model, device, 512, 512)\n",
        "\n",
        "  for k, summary in enumerate(batch_summaries):\n",
        "    df[\"summary\"][start_idx+k] = summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4JPoggxJkNq",
        "outputId": "c99f4d45-5842-48cd-91be-edc88ac383be"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/modeling_utils.py:784: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n",
            "<ipython-input-4-be131ef5b0d3>:44: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[\"summary\"][start_idx+k] = summary\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example Summarised Legal Case:\n",
        "\n",
        "This is an example of the first summarised legal case in the dataset.\n",
        "\n",
        "----\n"
      ],
      "metadata": {
        "id": "JSC_ink80484"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['summary'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "oZfbLjr7EJ09",
        "outputId": "7b2cbc57-0c73-41db-83ce-9a5d5c23ff2d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'On 5 July and 31 August 1990 the applicant was summoned to appear before the Helsinki City Court (raastuvanoikeus, rdstuvurätt, as from 1 December 1993 Helsinki District Court, käräjäoikeus, tingsrätt) indicted for several aggravated tax frauds. Furthermore, Chapter 16, Section 5, of the Code of Judicial Procedure provided: “When it is important to wait for a decision of another tribunal or some other body before a decision is given in a pending case, or when some other long-lasting impediment exists, a court may order that the hearing of the case will not be pursued until that obstacle ceases to exist.” According to Chapter 14, Section 7a (19.4.1991/708), of the Code of Judicial Procedure, which came into force on 1 April 1992, charges against defendants accused of committing the same offence must, in principle, be tried together. According to Chapter 14, Section 7a (19.4.1991/708), of the Code of Judicial Procedure, which came into force on 1 April 1992, charges against defendants accused of committing the same offence must, in principle, be tried together. The applicant sought leave to appeal from the Supreme Court (korkein oikeus, högsta domstolen) renewing his request that the length of the proceedings be taken into account in the assessment of his sentence. Furthermore, Chapter 16, Section 5, of the Code of Judicial Procedure provided: “When it is important to wait for a decision of another tribunal or some other body before a decision is given in a pending case, or when some other long-lasting impediment exists, a court may order that the hearing of the case will not be pursued until that obstacle ceases to exist.” According to Chapter 14, Section 7a (19.4.1991/708), of the Code of Judicial Procedure, which came into force on 1 April 1992, charges against defendants accused of committing the same offence must, in principle, be tried together. The applicant sought leave to appeal from the Supreme Court (korkein oikeus, högsta domstolen) renewing his request that the length of the proceedings be taken into account in the assessment of'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Inference\n",
        "---\n",
        "In the Inference section of our notebook, we import one of our pre-trained and optimized models for each of binary classification, multi-class classification, and regression, specifically tailored to the Long-T5 summarisation model. It is important to note that these models have been fine-tuned on our Long-T5 training sets. The binary classification model takes in summary information of legal cases as input and predicts whether any articles have been violated or not. Similarly, for multi-class classification, the model outputs predictions of which articles have been violated. We evaluate the performance of the model on a withheld and unseen test set, and demonstrate how we have applied the model to make predictions on new legal case summaries and interpret the results. This section highlights the practical use of our NLP techniques for automated legal analysis, demonstrating how they can provide rapid and trustworthy insights to legal practitioners."
      ],
      "metadata": {
        "id": "Bm1L1uOO-UGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cell for all the required functions\n",
        "\n",
        "class LegalBertBinaryCls(nn.Module):\n",
        "    \"\"\"\n",
        "    bert-small-uncased on binary classification.\n",
        "    \"\"\"\n",
        "    def __init__(self, legalbert):\n",
        "        super(LegalBertBinaryCls, self).__init__()\n",
        "        self.bert = legalbert \n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.linear = nn.Linear(self.bert.pooler.dense.out_features, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        losses, logits = self.bert(input_ids, attention_mask, return_dict=False)\n",
        "        outputs = self.dropout(logits)\n",
        "        outputs = self.linear(logits)\n",
        "        preds = self.sigmoid(outputs)\n",
        "\n",
        "        return preds\n",
        "    \n",
        "class LegalBertMultiCls(nn.Module):\n",
        "    \"\"\"\n",
        "    bert-small-uncased on multi-class classification.\n",
        "    \"\"\"\n",
        "    def __init__(self, legalbert, num_classes=23):\n",
        "        super(LegalBertMultiCls, self).__init__()\n",
        "        self.bert = legalbert \n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.linear = nn.Linear(self.bert.pooler.dense.out_features, num_classes)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        losses, logits = self.bert(input_ids, attention_mask, return_dict=False)\n",
        "        outputs = self.dropout(logits)\n",
        "        outputs = self.linear(logits)\n",
        "        preds = self.sigmoid(outputs)\n",
        "\n",
        "        return preds\n",
        "    \n",
        "class LegalBertRegression(nn.Module):\n",
        "    \"\"\"\n",
        "    bert-small-uncased on regression.\n",
        "    \"\"\"\n",
        "    def __init__(self, legalbert):\n",
        "        super(LegalBertRegression, self).__init__()\n",
        "        self.bert = legalbert \n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.linear = nn.Linear(self.bert.pooler.dense.out_features, 1)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        losses, logits = self.bert(input_ids, attention_mask, return_dict=False)\n",
        "        outputs = self.dropout(logits)\n",
        "        outputs = self.linear(logits)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "def get_model(task, model):\n",
        "    \"\"\"\n",
        "    Select the model based on the task.\n",
        "    Params:\n",
        "    `task` (str): the task to be performed\n",
        "    `model` (torch.nn.Module): the base model\n",
        "    \"\"\"\n",
        "    if task == \"binary_cls\":\n",
        "        model = LegalBertBinaryCls(model)\n",
        "    elif task == \"multi_cls\":\n",
        "        model = LegalBertMultiCls(model)\n",
        "    elif task == \"regression\":\n",
        "        model = LegalBertRegression(model)\n",
        "\n",
        "    return model\n",
        "\n",
        "def get_loss_func(task):\n",
        "    \"\"\"\n",
        "    Get the loss function based on the task.\n",
        "    Params:\n",
        "    `task` (str): the task to be performed\n",
        "    \"\"\"\n",
        "    if task == \"binary_cls\" or task == \"multi_cls\":\n",
        "        loss_func = nn.BCELoss()\n",
        "    elif task == \"regression\":\n",
        "        loss_func = nn.L1Loss()\n",
        "\n",
        "    return loss_func\n",
        "\n",
        "# label encoding\n",
        "article_dict = {'2': 0, '3': 1, '4': 2, '5': 3, '6': 4, '7': 5, '8': 6, '9': 7, '10': 8, '11': 9, '12': 10, '13': 11, '14': 12, '18': 13, '25': 14, '34': 15, '38': 16, '46': 17, 'P1': 18, 'P4': 19, 'P6': 20, 'P7': 21, 'P12': 22}\n",
        "\n",
        "def get_one_hot_labels(df, article_dict):\n",
        "    \"\"\"\n",
        "    Create a list of lists with a one-hot encoding of the articles violated for each row in the input dataframe\n",
        "    Params:\n",
        "    `df` (pd.DataFrame): dataframe containing the violated articles\n",
        "    `article_dict` (dict): dictionary mapping article names to indices\n",
        "    \"\"\"\n",
        "    article_dict = {\n",
        "        '2': 0, '3': 1, '4': 2, '5': 3, '6': 4, '7': 5, '8': 6, '9': 7, '10': 8, '11': 9, \n",
        "        '12': 10, '13': 11, '14': 12, '18': 13, '25': 14, '34': 15, '38': 16, '46': 17, 'P1': 18, 'P4': 19, \n",
        "        'P6': 20, 'P7': 21, 'P12': 22\n",
        "    }\n",
        "\n",
        "    labels = []\n",
        "\n",
        "    for articles in df[\"violated_articles\"]:\n",
        "        label = [int(key in articles) for key in article_dict.keys()]\n",
        "        labels.append(label)\n",
        "\n",
        "    return labels\n",
        "\n",
        "def load_data(folder=\"echr\", task=\"binary_cls\", anon=False):\n",
        "    \"\"\"\n",
        "    Load data from pickle files and return train, validation and test sets.\n",
        "    Params:\n",
        "    `folder` (str): folder containing the data\n",
        "    `task` (str): task to perform, either 'binary_cls', 'multi_cls' or 'regression'\n",
        "    `anon` (bool): whether to load the anonymised data or not\n",
        "    \"\"\"\n",
        "    if anon == False:\n",
        "        train_df = pd.read_pickle(f\"{folder}/non-anon_train.pkl\")\n",
        "        val_df = pd.read_pickle(f\"{folder}/non-anon_valid.pkl\")\n",
        "        test_df = pd.read_pickle(f\"{folder}/non-anon_test.pkl\")\n",
        "    else:\n",
        "        train_df = pd.read_pickle(f\"data/{folder}/anon_train.pkl\")\n",
        "        val_df = pd.read_pickle(f\"data/{folder}/anon_valid.pkl\")\n",
        "        test_df = pd.read_pickle(f\"data/{folder}/anon_test.pkl\")\n",
        "\n",
        "    if folder == \"echr\":\n",
        "        text_column = \"text\"\n",
        "    else:\n",
        "        text_column = \"summary\"\n",
        "\n",
        "    train_texts, val_texts, test_texts = train_df[text_column].tolist(), val_df[text_column].tolist(), test_df[text_column].tolist()\n",
        "\n",
        "    if task == \"binary_cls\":\n",
        "        train_labels = train_df[\"violated\"].astype(int).tolist()\n",
        "        val_labels = val_df[\"violated\"].astype(int).tolist()\n",
        "        test_labels = test_df[\"violated\"].astype(int).tolist()\n",
        "    elif task == \"multi_cls\":\n",
        "        train_labels = get_one_hot_labels(train_df, article_dict)\n",
        "        val_labels = get_one_hot_labels(val_df, article_dict)\n",
        "        test_labels = get_one_hot_labels(test_df, article_dict)\n",
        "    elif task == \"regression\":\n",
        "        train_labels = train_df[\"importance\"].astype(int).tolist()\n",
        "        val_labels = val_df[\"importance\"].astype(int).tolist()\n",
        "        test_labels = test_df[\"importance\"].astype(int).tolist()\n",
        "\n",
        "    return train_texts, train_labels, val_texts, val_labels, test_texts, test_labels\n",
        "\n",
        "def generate_tokens(tokenizer, texts, max_length=512):\n",
        "    \"\"\"\n",
        "    Tokenize the input texts.\n",
        "    Params:\n",
        "    `tokenizer` (transformers.PreTrainedTokenizer): tokenizer to use\n",
        "    `texts` (list): list of texts to tokenize\n",
        "    `max_length` (int): maximum length of the tokenized texts\n",
        "    \"\"\"\n",
        "    tokens = tokenizer.batch_encode_plus(texts, \n",
        "        return_tensors = \"pt\", \n",
        "        padding = \"max_length\",\n",
        "        truncation = True, \n",
        "        max_length = max_length, \n",
        "        pad_to_max_length = True, \n",
        "        return_token_type_ids = False\n",
        "    )\n",
        "\n",
        "    return tokens\n",
        "\n",
        "def create_dataloader(tokens, labels, batch_size, type):\n",
        "    \"\"\"\n",
        "    Create a dataloader for the input data.\n",
        "    Params:\n",
        "    `tokens` (torch.Tensor): tensor containing the tokenized texts\n",
        "    `labels` (torch.Tensor): tensor containing the labels\n",
        "    `batch_size` (int): batch size\n",
        "    `type` (str): type of dataloader to create, either 'train', 'val' or 'test'\n",
        "    \"\"\"\n",
        "    if not isinstance(labels[0], list):\n",
        "        labels = torch.tensor(labels).unsqueeze(1)\n",
        "    else:\n",
        "        labels = torch.tensor(labels)\n",
        "\n",
        "    data = TensorDataset(tokens.input_ids, tokens.attention_mask, labels)\n",
        "\n",
        "    if type == \"train\":\n",
        "        sampler = RandomSampler(data)\n",
        "        dataloader = DataLoader(data, sampler=sampler, batch_size=batch_size)\n",
        "    elif type == \"val\":\n",
        "        sampler = SequentialSampler(data)\n",
        "        dataloader = DataLoader(data, sampler=sampler, batch_size=batch_size)\n",
        "    elif type == \"test\":\n",
        "        dataloader = DataLoader(data, batch_size=batch_size)\n",
        "\n",
        "    return dataloader\n",
        "\n",
        "def test(test_loader, model, task, model_name):\n",
        "    \"\"\"\n",
        "    Test the inference model on the test set.\n",
        "    Params:\n",
        "    `test_loader` (torch.utils.data.DataLoader): dataloader for the test set\n",
        "    `model` (torch.nn.Module): the model to be tested\n",
        "    `task` (str): the task to be performed\n",
        "    `model_name` (str): the name of the model\n",
        "    \"\"\"\n",
        "    start = time.time()\n",
        "    # load trained model\n",
        "    model.load_state_dict(torch.load(model_name))\n",
        "\n",
        "    all_preds = torch.tensor([])\n",
        "    all_labels = torch.tensor([])\n",
        "    running_loss = 0\n",
        "\n",
        "    loss_func = get_loss_func(task)\n",
        "    model.eval()\n",
        "\n",
        "    # iterate over batches\n",
        "    for i, batch in enumerate(test_loader):\n",
        "        # progress update after every 100 batches.\n",
        "        if i % 100 == 0:\n",
        "            print(\"--> batch {:} of {:}.\".format(i, len(test_loader)))\n",
        "        # push the batch to gpu\n",
        "        batch = [r.to(device) for r in batch]\n",
        "        input_ids, attention_mask, labels = batch\n",
        "        with torch.no_grad():\n",
        "            # forward pass  \n",
        "            preds = model(input_ids, attention_mask)\n",
        "            preds, labels = preds.type(torch.FloatTensor), labels.type(torch.FloatTensor)\n",
        "            # compute the loss between actual and predicted values\n",
        "            loss = loss_func(preds, labels)\n",
        "            # add on to the total loss\n",
        "            running_loss += loss.item()\n",
        "            if task == \"binary_cls\" or task == \"multi_cls\":\n",
        "                preds = torch.round(preds)\n",
        "            all_preds = torch.cat((all_preds, preds), dim=0)\n",
        "            all_labels = torch.cat((all_labels, labels), dim=0)\n",
        "\n",
        "    running_loss = running_loss / len(test_loader)\n",
        "    print(f\"----> test loss {running_loss}\")\n",
        "    print(f\"----> time taken {time.time()-start}\")\n",
        "\n",
        "    return all_preds, all_labels, running_loss"
      ],
      "metadata": {
        "id": "BNi5szw-isOD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use gpu!\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Al3W8SaNLfaX",
        "outputId": "9751096a-b6c8-481c-ced0-7be1f1792af7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    print(\"=========================\")\n",
        "    print(\"script starts...\")\n",
        "\n",
        "    folder = \"long_t5_summary\"\n",
        "    tasks = [\"binary_cls\", \"multi_cls\", \"regression\"]\n",
        "    model_names = [\"/content/long_t5_binary_cls/long_t5_opt_binary_cls.pt\",\"/content/long_t5_binary_cls/long_t5_opt_multi_cls.pt\",\"/content/long_t5_binary_cls/long_t5_opt_regression.pt\" ]\n",
        "    max_seq_length = 512\n",
        "    batch_size = 4\n",
        "    pretrained_model = \"nlpaueb/legal-bert-small-uncased\"\n",
        "\n",
        "    print(f\"using {device}\")\n",
        "    print(f\"folder: {folder}\")\n",
        "    print(f\"We will be evaluating the following tasks: {tasks}\")\n",
        "\n",
        "    # loop through each task\n",
        "    for i, task in enumerate(tasks):\n",
        "        print(\"task: \", task)\n",
        "        # load data\n",
        "        train_texts, train_labels, val_texts, val_labels, test_texts, test_labels = load_data(folder, task)\n",
        "        # load model\n",
        "        model = AutoModel.from_pretrained(pretrained_model, return_dict=False)\n",
        "        # adapt model\n",
        "        model = get_model(task, model)\n",
        "        # move model to gpu\n",
        "        model.to(device)\n",
        "        # tokenizer\n",
        "        tokenizer = AutoTokenizer.from_pretrained(pretrained_model)\n",
        "        # generate tokens\n",
        "        test_tokens = generate_tokens(tokenizer, test_texts, max_seq_length)\n",
        "        # dataloader\n",
        "        test_loader = create_dataloader(test_tokens, test_labels, batch_size, type=\"test\")\n",
        "        # run test script\n",
        "        test_preds, test_labels, test_loss = test(test_loader, model, task, model_names[i])\n",
        "        # print results\n",
        "        if task == \"binary_cls\" or task == \"multi_cls\":\n",
        "            report = classification_report(test_labels, test_preds)\n",
        "            print(f'{task} classification report:')\n",
        "            print(report)\n",
        "        elif task == \"regression\":\n",
        "            mae = mean_absolute_error(test_labels, test_preds)\n",
        "            print(f'{task} mean absolute error:')\n",
        "            print(mae)\n",
        "\n",
        "    print(\"script finishes\")\n",
        "    print(\"=========================\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_IE8P_P6oxg",
        "outputId": "5a9a6310-6822-4b8d-a2fe-29d92f6a28e6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================\n",
            "script starts...\n",
            "using cuda\n",
            "folder: long_t5_summary\n",
            "We will be evaluating the following tasks: ['binary_cls', 'multi_cls', 'regression']\n",
            "task:  binary_cls\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at nlpaueb/legal-bert-small-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--> batch 0 of 750.\n",
            "--> batch 100 of 750.\n",
            "--> batch 200 of 750.\n",
            "--> batch 300 of 750.\n",
            "--> batch 400 of 750.\n",
            "--> batch 500 of 750.\n",
            "--> batch 600 of 750.\n",
            "--> batch 700 of 750.\n",
            "----> test loss 0.8703353334168593\n",
            "----> time taken 25.854230880737305\n",
            "binary_cls classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.40      0.58      0.48      1024\n",
            "         1.0       0.72      0.55      0.62      1974\n",
            "\n",
            "    accuracy                           0.56      2998\n",
            "   macro avg       0.56      0.57      0.55      2998\n",
            "weighted avg       0.61      0.56      0.57      2998\n",
            "\n",
            "task:  multi_cls\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at nlpaueb/legal-bert-small-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--> batch 0 of 750.\n",
            "--> batch 100 of 750.\n",
            "--> batch 200 of 750.\n",
            "--> batch 300 of 750.\n",
            "--> batch 400 of 750.\n",
            "--> batch 500 of 750.\n",
            "--> batch 600 of 750.\n",
            "--> batch 700 of 750.\n",
            "----> test loss 0.24676336768393714\n",
            "----> time taken 26.093497276306152\n",
            "multi_cls classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.48      0.48       118\n",
            "           1       0.60      0.43      0.50       524\n",
            "           2       0.00      0.00      0.00         3\n",
            "           3       0.68      0.43      0.53       383\n",
            "           4       0.54      0.51      0.53       726\n",
            "           5       0.00      0.00      0.00         5\n",
            "           6       0.34      0.20      0.26       215\n",
            "           7       0.31      0.24      0.27        17\n",
            "           8       0.54      0.24      0.33       105\n",
            "           9       0.57      0.30      0.39        54\n",
            "          10       0.00      0.00      0.00         1\n",
            "          11       0.39      0.17      0.24       322\n",
            "          12       0.32      0.17      0.23        40\n",
            "          13       0.00      0.00      0.00         5\n",
            "          14       0.00      0.00      0.00         0\n",
            "          15       0.18      0.06      0.09        35\n",
            "          16       0.00      0.00      0.00         4\n",
            "          17       0.00      0.00      0.00         0\n",
            "          18       0.46      0.21      0.29       297\n",
            "          19       0.00      0.00      0.00        16\n",
            "          20       0.00      0.00      0.00         2\n",
            "          21       0.00      0.00      0.00        14\n",
            "          22       0.00      0.00      0.00         3\n",
            "\n",
            "   micro avg       0.53      0.36      0.43      2889\n",
            "   macro avg       0.24      0.15      0.18      2889\n",
            "weighted avg       0.51      0.36      0.41      2889\n",
            " samples avg       0.28      0.25      0.25      2889\n",
            "\n",
            "task:  regression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Some weights of the model checkpoint at nlpaueb/legal-bert-small-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--> batch 0 of 750.\n",
            "--> batch 100 of 750.\n",
            "--> batch 200 of 750.\n",
            "--> batch 300 of 750.\n",
            "--> batch 400 of 750.\n",
            "--> batch 500 of 750.\n",
            "--> batch 600 of 750.\n",
            "--> batch 700 of 750.\n",
            "----> test loss 0.5627017760276795\n",
            "----> time taken 26.297304391860962\n",
            "regression mean absolute error:\n",
            "0.56305516\n",
            "script finishes\n",
            "=========================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All our code for this project can be found on our public github repo (https://github.com/rorycreedon/comp0087_assignment.git)."
      ],
      "metadata": {
        "id": "J1IuCuL25-jb"
      }
    }
  ]
}